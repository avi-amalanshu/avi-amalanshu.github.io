<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport", content="width=device-width", initial-scale=1">
  <script src="https://flackr.github.io/scroll-timeline/dist/scroll-timeline.js"></script>
  <title>Avi Amalanshu</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&display=swap" rel="stylesheet">
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Archivo+Black&family=Geologica&family=Noto+Sans+Mono:wght@200&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=Fira+Sans+Condensed:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap');
    html * {
      box-sizing: border-box;
      scroll-snap-type: y mandatory;
      font-family: "Fira Sans Condensed", sans-serif;
        font-weight: 100;
      font-optical-sizing: auto;
      font-style: normal;
      font-variation-settings:
        "wdth" 100;
    }

    b {
      font-weight: 400;
      font-style: normal;
      background-color: white;
      color: black;
    }

    @keyframes fadeInFromDark {
      from { opacity: 0; }
      to { opacity: 1; }
    }

    body {
      letter-spacing: normal;
      background-color: black;
      color: white;
      margin: 0;
      animation: fadeInFromDark ease 1s forwards;
    }

    nav {
      background: rgba(0, 0, 0, 0.75);
      width: 100%;
      height: 10vh;
      display: flex;
      align-items: center;
      justify-content: center;
      position: sticky;
      backdrop-filter: blur(0.0375rem);
      top: 0;
      z-index: 1000;
    }

    header {
      /*max-width: 100vw;*/
      width: 100%;
      height: 100vh;
      overflow-x: clip;
      position: relative;
    }

    @keyframes headerImgFade {
      25% { opacity: 0.4; }
      85%, 100% { opacity: 0; scale: 3; filter: blur(1rem);}
    }

    h1 {
      font-family: "Archivo Black", sans-serif;
      font-weight: 400;
      font-style: normal;
    }

    header > img {
      object-fit: cover;
      width: 100%;
      height: 100%;
      opacity: 0.2;
      position: absolute;
      inset: 0;
      z-index: -1;
      animation: headerImgFade 0.1ms linear forwards;

      overflow-x: clip;
      animation-timeline: view();
      animation-range: exit;
    }

    @keyframes fadeOut {
      to { opacity: 0; }
    }

    .header-content {
      position:relative;
      vertical-align: middle;
      overflow-x: clip;
      padding-block: 7rem;
      margin-block-end: 3rem;
      animation: fadeOut 0.1ms linear forwards;
      animation-timeline: view();
      animation-range: exit;
    }

    .header-content > h1 {
      font-size: 5vw;
      text-align: center;
      /*text-transform: full-width;*/
      color: white;
    }

    .header-content > p {
      font-family: "Noto Sans Mono", monospace;
      font-weight: 200;
      font-style: normal;
      font-size: 1.25vw;
      /*font-family: "Geologica", sans-serif;*/
      /*font-weight: 200;*/
      /*font-style: normal;*/
      /*font-size: 1.5vw;*/
      text-align: center;
      /*text-transform: full-width;*/
      color: white;
    }

    section {
      block-size: 100%;
      width: 60%;
      min-height: 100vh;
      margin: 0 auto;
      vertical-align: middle;
      /*scroll-snap-align: start;*/
      /*scroll-snap-stop: always;*/

      /*display: flex;*/
      align-items: center;
      justify-content: center;
    }

    @keyframes fadeIn {
      to { scale: 1; opacity: 1; }
    }

    section > img {
      display: block;
      max-width: 36vw;
      height: auto;
      margin-left: auto;
      margin-right: auto;
      scale: 0.8;
      opacity: 0;

      animation: fadeIn 0.1ms ease forwards;
      animation-timeline: view();
      animation-range: contain;
    }

    section > img.me {
      position: relative;
      width: 10vw;
      /*box-shadow: 0 0 8px 8px white inset;*/
      z-index: -1;
    }

    section > h1 {
      font-size: 1.75rem;
    }

    section > p {
      font-size: 0.875rem;
    }

    a:link {
      color: lightblue;
      background-color: transparent;
      text-decoration: none;
    }

    a:visited {
      color: lightblue;
      background-color: transparent;
      text-decoration: none;
    }

    a:hover {
      color: lightskyblue;
      background-color: transparent;
      text-decoration: underline;
    }

    a:active {
      color: gray;
      background-color: transparent;
      text-decoration: underline;
    }

    span.email b {
      display: none;
    }

  </style>
</head>

<body>

<nav> <a href="#about">about</a> | <a href="#papers">papers</a> | <a href="#projects">more projects</a> |
  <a href="#contact">find me</a> | <a href="#fun">fun</a> | <a href="https://github.com/avi-amalanshu">github</a> | <a href="cv.pdf">cv</a> </nav>

<header>
  <img src="assets/images/decoration/kgproof.png" alt=""/>
  <div class="header-content">
    <h1>the avi amalanshu lair</h1>
    <p>welcome. i'm a fifth year masters student studying vision & intelligent systems at IIT Kharagpur.</p>
    <p>i like computers. i really like computers that learn fast. <a href="cv.pdf" style="font-family: 'Noto Sans Mono', monospace">here is my curriculum vitae.</a></p>
    <p>let's get to know each other. please scroll down, or use the navbar above.</p>
    <p style="font-size: 0.75vw">you may prefer the <a href="home.html" style="font-family: 'Noto Sans Mono', monospace">older, static version of the website</a> if you
      suffer from motion sickness.</p>
  </div>
</header>

<section id="about">
  <h1>About Me</h1>
  <p>
    I'm an undergrad at <a href="http://www.iitkgp.ac.in/">IIT Kharagpur</a>. I'll graduate in 2025 with
    a B.Tech in ECE and M.Tech in Vision & Intelligent Systems.
    I'm broadly interested in MLSys. My overarching goal is to develop AI algorithms and systems which are <b>democratic
    &amp; usable</b>. My feeble attempts at doing so thus far have been supported by Boeing, IITKGPF-USA and the NSF.

    This is me. </p>

    <img src="assets/images/decoration/image.png" class="me" alt=""/>

    <p>
      I am particularly interested in these closely related avenues towards "democratization and usability":<br><br>
      I see <b>Neurosymbolic Learning</b> as the frontier of ML research. Causal System 2 insight might help models become
      leaner, generalize from less data and align with human values. Distilling neural agents and bootstrapping them with
      solvers enables scientific discovery and safety-critical cyber-physical applications.<br><br>
      <b>Distributed/Parallel/Pipelined Optimization</b> will allow large-scale participation in ML training and enable
      low-resource users to train their own state-of-the-art models. For that, it is necessary to investigate such
      methods that maximize privacy and tolerate faults.<br><br>
      A common theme tying these together is <b>brain-inspired computation</b>. Now, I'm not one
      to restrict our discrete, verifiable computer programs to follow natural, error-prone stochastic patterns. But they
      can provide some select properties and heuristics. Linguists say we're born with a "universal grammar" that provides
      a foundation that we wire up as we acquire language, allowing a distinct efficiency. Our neurons don't wait for
      a supervisory signal to update, unlike backprop. Brain ontogenesis works even though it
      doesn't get to sample an exponential search space. Programs could benefit from such statistical modelling.
      <br><br>
      I spent my summers with <a href="https://davidinouye.com">Prof. David Inouye</a> at
      Purdue working on greedy & distributed optimization and at <a href="https://theairlab.com">
      AirLab</a>, CMU working on ILP, LLMs and map-matching. At KGP, I lead the AGV undergrad group's DL team on
      scene understanding, IRL and FL.<br><br>
      In my free time, I code goofy mini-projects, most of which never make it to my GitHub out of embarassment. I enjoy
      playing and watching sports (especially basketball). I also spread vitriol online through my blog. I've represented
      IITKGP twice in word games at the collegiate level. Recently, I've taken a liking to competitive programming and CTFs.
      I did say I liked computers.<br><br>
      I grew up in the wonderful Hauz Khas, New Delhi, India. During breaks, you'll find me there hanging out with
      old friends, my parents and the dog. I was born in Baltimore and spent some early years in Santa Clara. I guess
      that makes me an expat/international student from India's perspective.
  </p>
  <p style="font-size: 0.75vw; text-align: center">
    <a href="https://avi-amalanshu.github.io">back (home)</a> &#183; <a href="research.html">detailed statement
  + interests</a> &#183; <a href="#papers">forth (papers)</a>
  </p>
</section>

<section id="papers">
  <h1>Papers</h1>
  <p>
    If you scroll down, you'll find abstracts for my publications so far.
  </p>
  <p>
    This includes most of my conference papers, journal papers, workshop papers, preprints.
  </p>
  <p>
    [Note] This section is WIP. Previously, this was a key projects section. I am in the process of separating the
    papers and projects sections.
  </p>
  <p style="font-size: 0.75vw; text-align: center">
    <a href="#about">back (about)</a> &#183; <a href="research.html#papers">more projects</a> &#183;
    <a href="#AI airport">forth (key project 1: AI airport)</a>
  </p>
</section>

<section id="AI airport">
  <h1>Intent Prediction in Terminal Airspace (May '24 -- ongoing)</h1>
  <img src="assets/images/proj/boeing.png" alt="Amelia" style="filter: invert(100%);"/>
  <p>
    This project is still ongoing. I will update this section once we submit our paper.
  </p>
  <p>
    My work is to advance a project that aims to forecast and analyze aircraft activity at airports. My goal is: given
    a long and complex natural-language rulebook and a view of the airport, to reliably determine if any rule is about
    to be broken.
  </p>
  <p>
    Existing work on this project includes a large-scale dataset and a software repository which processes the data,
    predicts trajectories, performs visualizations and simulations etc. Besides my work on rule-checking, I am also
    adding a few features to the software repository: semantic grounding for data and semantic-aware trajectory refinement.
  </p>
  <p style="font-size: 0.75vw; text-align: center">
    <a href="#papers">back (projects)</a> &#183; <a href="research.html#papers">more projects</a> &#183;
    <a href="#DVFL">forth (key project 2: dvfl)</a>
  </p>
</section>
<section id="DVFL" style="height: 120vh">
  <h1>Decoupled Vertical Federated Learning (Aug '23 -- Nov '23)</h1>
  <img src="assets/images/proj/dvfl-main.svg" alt="DVFL"/>
  <p>
    Vertical Federated Learning (VFL) is an emergent distributed machine learning paradigm wherein owners of disjoint
    features of a common set of entities collaborate to learn a global model without sharing data. In VFL, a host client
    owns data labels for each entity and learns a final representation based on intermediate local representations from
    all guest clients. Therefore, the host is a single point of failure and label feedback can be used by malicious
    guest clients to infer private features. Requiring all participants to remain active and trustworthy throughout the
    entire training process is generally impractical and altogether infeasible outside of controlled environments. We
    propose Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each model on its own objective,
    DVFL allows for decentralized aggregation and isolation between feature learning and label supervision. With these
    properties, DVFL is fault-tolerant and secure. We implement DVFL to train split neural networks and show that model
    performance is comparable to VFL on a variety of classification datasets.
  </p>
  <p>
    This work is currently under peer review. Preprint below (to be revised soon). I also presented an early sketch of
    the idea at the SURF Symposium at Purdue University.
  </p>
  <img src="assets/images/proj/DVFL-cropped.png" style="height: 25vh" alt="my poster"/>
  <p>
    This was my Bachelor's thesis. I completed a two-semester track thesis in one. I picked this problem, formulated the
    solution, designed & programmed the experiments and wrote the paper. Since the thesis submission, I've been trying to
    add more datasets and models and get it accepted at a conference. Thanks to <a href="https://yashsirvi.github.io">Yash</a>
    for helping out with some of the legwork since I didn't have as much time during the next semester to do it all alone.
    Thanks also to Profs. Inouye and <a href="https://sites.google.com/view/rjithin">Jithin R</a> for their valuable guidance.
  </p>
  <p><a href="https://arxiv.org/pdf/2403.03871">Report (preprint, under peer review)</a></p>
  <p style="font-size: 0.75vw; text-align: center">
    <a href="#AI airport">back (key project 1: AI airport)</a> &#183; <a href="research.html#papers">more projects</a> &#183;
    <a href="#IL">forth (key project 3: internet learning)</a>

  </p>
</section>
<section id="IL">
  <h1>Internet Learning (May '23 -- Jul '23)</h1>
  <img src="assets/images/proj/IL.png" alt="IL" style="filter: invert(100%);"/>
  <p>
    Distributed machine learning has grown in popularity due to data privacy, edge computing, and large model training.
    A subset of this class, Vertical Federated learning (VFL), aims to provide privacy guarantees in the scenario where
    each party shares the same sample space but only holds a subset of features. While VFL tackles key privacy
    challenges, it often assumes perfect hardware or communication (and may perform poorly under other conditions).
    This assumption hinders the broad deployment of VFL, particularly on edge devices, which may need to conserve power
    and may connect or disconnect at any time. To address this gap, we define the paradigm of Internet Learning (IL),
    which defines a context, of which VFL is a subset, and puts good performance under extreme dynamic condition of data
    entities as the primary goal. As IL represents a fundamentally different paradigm, it will likely require novel
    learning algorithms beyond end-to-end backpropagation, which requires careful synchronization across devices. In
    light of this, we provide some potential approaches for the IL context and present preliminary analysis and
    experimental results on a toy problem.
  </p>
  <p>
    This was the first bit of my work as a Summer Undergraduate Research Fellow at Purdue University. I helped Prof.
    Inouye design and program the experiments, and wrote the appendix and relevant sections of the paper. I also wrote
    an intermediate revision of the submission from scratch. This work was accepted to an ICML 2023 workshop.
  </p>
  <p><a href="https://openreview.net/pdf?id=75PEgr4xTl">Report (ICML'23 LLW)</a></p>
  <p style="font-size: 0.75vw; text-align: center">
    <a href="#DVFL">back (key project 2: dvfl)</a> &#183; <a href="research.html#papers">more projects</a> &#183;
    <a href="#contact">contact</a>
  </p>
</section>
<section id="projects">
  <h1>More Projects</h1>
  <p>
    I have done far too many silly little projects to list. In this section [WIP], I'm going to enumerate some of the
    more interesting ones. These include unsubmitted research projects, personal projects and a smattering of course projects.
  </p>
   <p>
    <b>What to expect here: </b>I've been programming in C/C++ since the 8th grade and Python since my first year of undergrad. I also have a
    penchant for niche technologies. Sometimes I go out of my way to find cool stuff to implement in unpopular
    frameworks and languages. But since most of my significant work is related to machine learning, my GitHub is sadly
    whitewashed in Python.
  </p>
  <p>
    I guess I also kinda familiar with Prolog now. I also know some bash,
    asm (8051, x86, hopefully some RISC stuff soon) and ostensibly even Verilog. When I get time I want to get better at
    OCaml, Rust and Scala.
  </p>
  <p>
    I'm comfortable with C++'s standard libraries and actively studying some implementations of low-level libraries in C.
    I also intend to study CUDA programming in the near future. I'm well-versed in the typical ML/data pipeline for Python
    with PyTorch (including Geometric and Lightning), scikit, Pandas and what have you. I also use some security tools
    for CTFs like radare2, pwntools and so on.
  </p>
  <p>
    I'd also like to think I'm a good technical writer. I've got a few peer reviewed works under my belt.
  </p>
</section>
<section id="contact">
  <h1>Online Presence</h1>
  <p>My e-mail is <span class="email">avi.amalanshu@kgpian.<b>iitkgp.</b>iitkgp.ac.<b>co.</b>in.<b>.com</b></span>
    I anticipate your hate mail. </p>
  <p>My email and <a href="https://linkedin.com/in/avi-amalanshu">LinkedIn</a> are probably the easiest way to
  get a hold of me.</p>
  <p>I also have a <a href="https://twitter.com/avi_amalanshu">Twitter (avi_amalanshu)</a> but I don't really use it.</p>
  <p>Check out <a href="https://medium.com/@malansh">my blog: malansh on Medium</a>. I plan to start writing on it again
    when I'm a little more free, say Winter 2024. Topics I have in mind cover a mix of general advice, opinion pieces,
  and academic nerdery. (Information Geometry, anyone?)</p>
  <p>I'm always on the lookout for interesting puzzles and research problems, especially stuff that's interdisciplinary
    or niche (underappreciated). Let's talk if you have something interesting and can use my contributions. </p>
  <p>I love handing out advice and mentoring (to the extent that I often do so unsolicited). So feel free to
    solicit if you're interested! Be it JEE prep, handling acads + research at IIT, and of course, breaking into fields
    I'm working in.</p>
  <p><b>I'm graduating in 2025 and I'm looking for opportunities. Please reach out.</b></p>

  <p style="font-size: 0.75vw; text-align: center">
    <a href="#IL">back (key project 3: internet learning)</a> &#183; <a href="https://avi-amalanshu.github.io">back to
    top</a>
  </p>
  <h2><a href="https://linkedin.com/in/avi-amalanshu">linkedin</a>
  | <a href="https://twitter.com/avi_amalanshu">twitter</a> | <a href="https://github.com/avi-amalanshu">github</a>
  | <a href="https://medium.com/@malansh">blog</a> | <a href="cv.pdf">cv</a></h2>
</section>
</body>

</html>