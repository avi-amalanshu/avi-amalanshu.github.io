<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Avi's Static Website</title>
    <style>
        a:link {
            color:#BE0FFF;
        }
        @font-face {
            font-family: 'DOS';
            src: url('assets/fonts/DOS.ttf') format('truetype');
            font-weight: normal;
            font-style: normal;
        }
        b {
            color:#BE0FFF
        }
        h3 {
            color:#BE0FFF
        }
        pre {
            font-family: 'DOS', monospace;
        }
    </style>
</head>
<body style="background-color: #000000; color: #00BEFF; font-family: 'DOS', Courier, monospace;">

    <pre>
    ==============================================
    ||                                          ||
    ||   <a href="index.html">CLICK: COOLER VERSION OF THE WEBSITE</a>   ||
    ||                                          ||
    ==============================================
    </pre>

    <table width="100%" border="1" cellspacing="0" cellpadding="5" style="border-color:#BE0FFF;">
        <tr>
            <td colspan="2" align="center" style="background-color:#000071;">
                <h2 style="color:#00BEFF;">Welcome to the Avi Portal...<span id="blink_text">â–ˆ</span></h2>
            </td>
        </tr>
        <tr>
            <td width="30%" valign="top" rowspan="5">
                <img src="assets/images/decoration/cooler_image.png" alt="Avatar" width="200" height="200">
            </td>
            <td valign="top">
                <p>
					Greetings, traveler of the digital realms. I am Avi Amalanshu of CMU (MSML), former dual-degree
					(5-year B.Tech + M.Tech) at the ECE department, IIT Kharagpur. My vision is that one day you and I
                    can train and infer from our own AI agents aligned to our own values without bearing the cost to
                    throw half the internet on a bazillion GPUs for a whole year.</p>
				<p>
					I spent last summer at AirLab, CMU working on map matching and bootstrapping LLMs with inductive logic
                    programming. Before, I worked with Prof. David Inouye at Purdue on greedy/bioplausible and
                    distributed learning over dynamic and unreliable networks. At IIT-KGP, I led the AGV.AI
                    undergrad AI/robotics group and worked with Prof. Saumik Bhattacharya on neurosymbolic learning and
                    conformal prediction. I'm fortunate to have been supported by Boeing, a GK Fellowhsip from
					IIT-KGP Foundation USA, and a NSF REU in my undergrad research.
				</p>
            </td>
        </tr>
    </table>

    <pre>
    ==============================================
    ||                                          ||
    ||            RESEARCH INTERESTS            ||
    ||                                          ||
    ==============================================
    </pre>

    <ul>
        <li>Neurosymbolic Programming</li>
        <li>Systems-aware Learning and Optimization Algorithms</li>
    </ul>

<!--    <pre>-->
<!--    ==============================================-->
<!--    ||                                          ||-->
<!--    ||       PUBLICATIONS, PREPRINTS, ETC       ||-->
<!--    ||                                          ||-->
<!--    ==============================================-->
<!--    </pre>-->
<!--These are placeholders.-->
<!--    <ul>-->
<!--        <li><b>"The Cybernetic Dream: AI in the Neural Net"</b> - Journal of Cybernetics, 2023</li>-->
<!--        <li><b>"Quantum Codes in the Post-Quantum Era"</b> - Quantum Computing Review, 2022</li>-->
<!--        <li><b>"Synthwave and its Impact on Digital Aesthetics"</b> - CyberCulture Journal, 2021</li>-->
<!--    </ul>-->

    <pre>
    ==============================================
    ||                                          ||
    ||                 PROJECTS                 ||
    ||                                          ||
    ==============================================
    </pre>

    <table width="100%" border="1" cellspacing="0" cellpadding="5" style="border-color:#BE00FF;" id="projects">
        <tr>
            <td width="30%" valign="top">
                <img src="assets/images/proj/mtp.png"
                     alt="MTP"
                     style="
                        /*filter: invert(100%);*/
                        display:block;
                        max-width: 100%;
                        max-height: 100%;
                        width: auto;
                        margin: 0 auto;
                ">
            </td>
            <td valign="top">
                <h3>An Information-Theoretic Bridge Between Neural and Symbolic AI</h3>
                <p>
                    Neural agents are great at System 1 thinking: fast, intuitive, statistical.
                    Not so much at System 2 reasoning, which is slow, deliberate and logical.
                    <br>
                    <br>
                    Our brains can learn from remarkably few samples and make interpretable, verifiable decisions based
                    on sound logical reasoning. The best of foundation models even after being trained on unfathomable
                    amounts of data are not remotely reliable, even with fancy feedback-loop-chain-of-thought prompt
                    tricks.
                    <br>
                    <br>
                    So how do we get there?
                    <br>
                    Optimizing over discrete logic typically implies a combinatorial search is needed somewhere--
                    probably NP hard, not good. Can we make things better by modeling probabilistic logical distributions?
                    <br>
                    <br>
                    Manuscript under preparation.
                </p>
            </td>
        </tr>
        <tr>
            <td width="30%" valign="top">
                <img src="assets/images/proj/boeing.png"
                     alt="Project 2"
                     style="
                        max-width: 100%;
                        filter: invert(100%);
                        display:block;
                        max-height: 100%;
                        width: auto;
                        margin: 0 auto;
                ">
            </td>
            <td valign="top">
                <h3>Amelia</h3>
                <p>
                    Intent Prediction for Airport Surface Operations.<br><br>
                    My role in this large-scale Boeing project was to come up with an efficient map-matching algorithm to
                    induce GIS information into a trajectory prediction model. Also, a way to use English rules via LLM
                    as a heuristic for procedural bias in Popper, an inductive logic programming system.
                </p>
            </td>
        </tr>
		<tr>
            <td width="30%" valign="top">
                <img src="assets/images/proj/vfl_fedvision.drawio-1-1-2.pdf"
                     alt="Entity Augmentation"
                     style="
                        filter: invert(100%);
                        display:block;
                        max-width: 100%;
                        max-height: 100%;
                        width: auto;
                        margin: 0 auto;
                ">
            </td>
            <td valign="top">
                <h3>Entity Augmentation</h3>
                <p>
                    Imagine a database whose columns belong to different organizations.
                    <br>
                    <br>
                    How do you learn something meaningful in this system? Sure, you could collect all the
                    features at a central location and use standard machine learning. But what if they don't share?
                    <br>
                    Vertical Federated Learning is intricately coordinated. You need to figure out rows everyone knows some features
                    for (without leaking the keys). Then, on every training iteration you need to arrange matters so that
                    everyone is passing their features pertaining to the same key, so that the aggregator knows what to
                    predict.
                    <br>
                    <br>
                    Or, you could just use Entity Augmentation.
                    <br>
                    GLOW @ IJCAI 2024 (Archival) and HoTDiML @ ICDCS 2025
                </p>
            </td>
        </tr>
		<tr>
            <td width="30%" valign="top">
                <img src="assets/images/proj/dvfl-main.svg"
                     alt="DVFL"
                     style="
                        display:block;
                        max-width: 100%;
                        max-height: 100%;
                        width: auto;
                        margin: 0 auto;
                ">
            </td>
            <td valign="top">
                <h3>Decoupled Vertical Federated Learning</h3>
                <p>
                    Vertical Federated Learning is not easy.
                    <br>
                    <br>
                    All it takes is one connection or participant to fail and the whole thing crashes. Also, if one of
                    your participants is curious, they can learn a lot about others' data from gradients the aggregator
                    sends them. And of course there's the whole bore of entity alignment (and therefore limitations on
                    sample size). It's hard enough cross-silo. Forget about scaling up.
                    <br>
                    <br>
                    Try Decoupled Vertical Federated Learning instead.
                    <br>
                    arXiv (short version in SSL @ NIPS 2024)
                </p>
            </td>
        </tr>
		<tr>
            <td width="30%" valign="top">
                <img src="assets/images/proj/IL.png"
                     alt="IL"
                     style="
                        filter: invert(100%);
                        display:block;
                        max-width: 100%;
                        max-height: 100%;
                        width: auto;
                        margin: 0 auto;
                ">
            </td>
            <td valign="top">
                <h3>Internet Learning</h3>
                <p>
                    We're wasting the Internet by merely passing data around. Why don't we compute, too?
                    <br>
                    <br>
                    Internet Learning is a paradigm for learning over decentralized networks. Our baseline proposal is
                    a collaborative backpropagation over the whole network. But you are encouraged to propose something
                    better.
                    <br>
                    Learning on dynamic networks with unreliable and unavailable edge computation is not trivial. Here's
                    a first step towards fixing that.
                    <br>
                    LLW @ ICML 2023
                </p>
            </td>
        </tr>
    </table>
    <ul>
        <li>
            More Projects:
            <ul>
                <li>
                    Ongoing: top secret!
                </li>
                <li>
                    Previous: see <a href="workarchive.html">here</a>.
                </li>
            </ul>
        </li>
    </ul>

    <pre>
    ==============================================
    ||                                          ||
    ||               MISCELLANEOUS              ||
    ||                                          ||
    ==============================================
    </pre>
    <p>
        These are placeholders.
    </p>
    <ul>
        <li>Contributor to the <b>Cyberpunk 2077 Modding Community</b></li>
        <li>Organizer of the annual <b>Vaporwave Music Festival</b></li>
        <li>Member of the <b>Digital Rights Advocacy Group</b></li>
    </ul>

    <pre>
    ==============================================
    ||                                          ||
    ||                 CONTACT                  ||
    ||                                          ||
    ==============================================
    </pre>
    <ul>
        <li>
            See <a href="index.html#contact">here</a>.
        </li>
    </ul>
    <pre>
    ==============================================
    ||                                          ||
    ||        LAST UPDATED: MAY 16 2025         ||
    ||                                          ||
    ==============================================
    </pre>

</body>
</html>